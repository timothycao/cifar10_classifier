{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-09T17:10:45.983968Z",
     "iopub.status.busy": "2025-03-09T17:10:45.983678Z",
     "iopub.status.idle": "2025-03-09T17:10:46.976473Z",
     "shell.execute_reply": "2025-03-09T17:10:46.975571Z",
     "shell.execute_reply.started": "2025-03-09T17:10:45.983936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_1\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_2\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/batches.meta\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/test_batch\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_3\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_5\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/data_batch_4\n",
      "/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/readme.html\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T17:10:48.316996Z",
     "iopub.status.busy": "2025-03-09T17:10:48.316595Z",
     "iopub.status.idle": "2025-03-09T17:10:49.125703Z",
     "shell.execute_reply": "2025-03-09T17:10:49.124658Z",
     "shell.execute_reply.started": "2025-03-09T17:10:48.316965Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cifar10_classifier'...\n",
      "remote: Enumerating objects: 90, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
      "remote: Total 90 (delta 51), reused 65 (delta 26), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (90/90), 23.59 KiB | 3.93 MiB/s, done.\n",
      "Resolving deltas: 100% (51/51), done.\n",
      "/kaggle/working/cifar10_classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/cifar10_classifier.git\n",
    "%cd cifar10_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T17:11:00.832217Z",
     "iopub.status.busy": "2025-03-09T17:11:00.831905Z",
     "iopub.status.idle": "2025-03-09T17:11:06.642295Z",
     "shell.execute_reply": "2025-03-09T17:11:06.641471Z",
     "shell.execute_reply.started": "2025-03-09T17:11:00.832189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 4848027\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from model import create_model\n",
    "from train import main as train\n",
    "from inference import main as inference\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "MODEL_NAME = 'ResNetCustom'\n",
    "BLOCK_TYPE = 'bottleneck'\n",
    "NUM_BLOCKS_PER_LAYER = [3, 4, 6, 3]\n",
    "NUM_CHANNELS_PER_LAYER = [29, 58, 116, 232]\n",
    "KERNEL_SIZE_PER_LAYER = [3, 3, 3, 3]\n",
    "SKIP_KERNEL_SIZE_PER_LAYER = [1, 1, 1, 1]\n",
    "EXPANSION = 4\n",
    "POOL_SIZE = 1\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 100\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 100\n",
    "AUGMENTATIONS = [\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    transforms.RandomGrayscale(p=0.2)\n",
    "]\n",
    "SAVE_MODE = 'best'  # Options: 'best', 'every'\n",
    "SAVE_EVERY_N = 1\n",
    "\n",
    "# Initialize model\n",
    "try:\n",
    "    model = create_model(\n",
    "        name=MODEL_NAME,\n",
    "        block_type=BLOCK_TYPE,\n",
    "        blocks_per_layer=NUM_BLOCKS_PER_LAYER,\n",
    "        channels_per_layer=NUM_CHANNELS_PER_LAYER,\n",
    "        kernels_per_layer=KERNEL_SIZE_PER_LAYER,\n",
    "        skip_kernels_per_layer=SKIP_KERNEL_SIZE_PER_LAYER,\n",
    "        expansion=EXPANSION,\n",
    "        pool_size=POOL_SIZE\n",
    "    )\n",
    "    print('Total model parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "except AssertionError as e:\n",
    "    print(f'Failed to create model: {e}')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T17:11:12.737800Z",
     "iopub.status.busy": "2025-03-09T17:11:12.737304Z",
     "iopub.status.idle": "2025-03-09T18:58:05.250812Z",
     "shell.execute_reply": "2025-03-09T18:58:05.249901Z",
     "shell.execute_reply.started": "2025-03-09T17:11:12.737772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model parameters: 4848027\n",
      "Loading data...\n",
      "Preprocessing pipeline:\n",
      " Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomCrop(size=(32, 32), padding=4)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
      "    RandomAffine(degrees=[-10.0, 10.0], translate=(0.1, 0.1), scale=(0.8, 1.2))\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
      "    RandomGrayscale(p=0.2)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initializing model...\n",
      "Training model...\n",
      "\n",
      "Epoch: 1/100      LR: 0.01000\n",
      "TRAIN: Loss: 2.09 Acc: 22.75%\n",
      "TEST:  Loss: 1.70 Acc: 37.43%\n",
      "\n",
      "Epoch: 2/100      LR: 0.01000\n",
      "TRAIN: Loss: 1.81 Acc: 33.58%\n",
      "TEST:  Loss: 1.64 Acc: 38.35%\n",
      "\n",
      "Epoch: 3/100      LR: 0.00999\n",
      "TRAIN: Loss: 1.62 Acc: 41.11%\n",
      "TEST:  Loss: 1.54 Acc: 51.36%\n",
      "\n",
      "Epoch: 4/100      LR: 0.00998\n",
      "TRAIN: Loss: 1.46 Acc: 48.00%\n",
      "TEST:  Loss: 1.16 Acc: 59.39%\n",
      "\n",
      "Epoch: 5/100      LR: 0.00996\n",
      "TRAIN: Loss: 1.32 Acc: 53.32%\n",
      "TEST:  Loss: 1.12 Acc: 62.01%\n",
      "\n",
      "Epoch: 6/100      LR: 0.00994\n",
      "TRAIN: Loss: 1.21 Acc: 57.17%\n",
      "TEST:  Loss: 0.97 Acc: 66.31%\n",
      "\n",
      "Epoch: 7/100      LR: 0.00991\n",
      "TRAIN: Loss: 1.14 Acc: 60.07%\n",
      "TEST:  Loss: 0.91 Acc: 68.64%\n",
      "\n",
      "Epoch: 8/100      LR: 0.00988\n",
      "TRAIN: Loss: 1.09 Acc: 62.05%\n",
      "TEST:  Loss: 0.79 Acc: 72.67%\n",
      "\n",
      "Epoch: 9/100      LR: 0.00984\n",
      "TRAIN: Loss: 1.03 Acc: 63.92%\n",
      "TEST:  Loss: 0.73 Acc: 75.16%\n",
      "\n",
      "Epoch: 10/100     LR: 0.00980\n",
      "TRAIN: Loss: 0.99 Acc: 65.36%\n",
      "TEST:  Loss: 0.78 Acc: 73.03%\n",
      "\n",
      "Epoch: 11/100     LR: 0.00976\n",
      "TRAIN: Loss: 0.96 Acc: 66.43%\n",
      "TEST:  Loss: 0.73 Acc: 75.23%\n",
      "\n",
      "Epoch: 12/100     LR: 0.00970\n",
      "TRAIN: Loss: 0.94 Acc: 67.41%\n",
      "TEST:  Loss: 0.77 Acc: 73.54%\n",
      "\n",
      "Epoch: 13/100     LR: 0.00965\n",
      "TRAIN: Loss: 0.91 Acc: 68.48%\n",
      "TEST:  Loss: 0.68 Acc: 76.44%\n",
      "\n",
      "Epoch: 14/100     LR: 0.00959\n",
      "TRAIN: Loss: 0.89 Acc: 69.22%\n",
      "TEST:  Loss: 0.61 Acc: 79.46%\n",
      "\n",
      "Epoch: 15/100     LR: 0.00952\n",
      "TRAIN: Loss: 0.86 Acc: 70.07%\n",
      "TEST:  Loss: 0.61 Acc: 79.33%\n",
      "\n",
      "Epoch: 16/100     LR: 0.00946\n",
      "TRAIN: Loss: 0.83 Acc: 71.06%\n",
      "TEST:  Loss: 0.66 Acc: 78.12%\n",
      "\n",
      "Epoch: 17/100     LR: 0.00938\n",
      "TRAIN: Loss: 0.82 Acc: 71.13%\n",
      "TEST:  Loss: 0.69 Acc: 77.50%\n",
      "\n",
      "Epoch: 18/100     LR: 0.00930\n",
      "TRAIN: Loss: 0.81 Acc: 71.76%\n",
      "TEST:  Loss: 0.57 Acc: 80.96%\n",
      "\n",
      "Epoch: 19/100     LR: 0.00922\n",
      "TRAIN: Loss: 0.79 Acc: 72.63%\n",
      "TEST:  Loss: 0.56 Acc: 80.95%\n",
      "\n",
      "Epoch: 20/100     LR: 0.00914\n",
      "TRAIN: Loss: 0.78 Acc: 73.05%\n",
      "TEST:  Loss: 0.55 Acc: 81.11%\n",
      "\n",
      "Epoch: 21/100     LR: 0.00905\n",
      "TRAIN: Loss: 0.76 Acc: 73.62%\n",
      "TEST:  Loss: 0.58 Acc: 80.25%\n",
      "\n",
      "Epoch: 22/100     LR: 0.00895\n",
      "TRAIN: Loss: 0.76 Acc: 73.88%\n",
      "TEST:  Loss: 0.51 Acc: 83.02%\n",
      "\n",
      "Epoch: 23/100     LR: 0.00885\n",
      "TRAIN: Loss: 0.74 Acc: 74.19%\n",
      "TEST:  Loss: 0.48 Acc: 83.60%\n",
      "\n",
      "Epoch: 24/100     LR: 0.00875\n",
      "TRAIN: Loss: 0.73 Acc: 74.92%\n",
      "TEST:  Loss: 0.54 Acc: 81.48%\n",
      "\n",
      "Epoch: 25/100     LR: 0.00864\n",
      "TRAIN: Loss: 0.71 Acc: 75.40%\n",
      "TEST:  Loss: 0.48 Acc: 83.61%\n",
      "\n",
      "Epoch: 26/100     LR: 0.00854\n",
      "TRAIN: Loss: 0.71 Acc: 75.44%\n",
      "TEST:  Loss: 0.48 Acc: 83.48%\n",
      "\n",
      "Epoch: 27/100     LR: 0.00842\n",
      "TRAIN: Loss: 0.69 Acc: 75.89%\n",
      "TEST:  Loss: 0.50 Acc: 83.18%\n",
      "\n",
      "Epoch: 28/100     LR: 0.00831\n",
      "TRAIN: Loss: 0.68 Acc: 76.32%\n",
      "TEST:  Loss: 0.55 Acc: 82.27%\n",
      "\n",
      "Epoch: 29/100     LR: 0.00819\n",
      "TRAIN: Loss: 0.68 Acc: 76.27%\n",
      "TEST:  Loss: 0.43 Acc: 85.42%\n",
      "\n",
      "Epoch: 30/100     LR: 0.00806\n",
      "TRAIN: Loss: 0.67 Acc: 76.85%\n",
      "TEST:  Loss: 0.43 Acc: 84.77%\n",
      "\n",
      "Epoch: 31/100     LR: 0.00794\n",
      "TRAIN: Loss: 0.66 Acc: 77.15%\n",
      "TEST:  Loss: 0.45 Acc: 84.80%\n",
      "\n",
      "Epoch: 32/100     LR: 0.00781\n",
      "TRAIN: Loss: 0.66 Acc: 77.10%\n",
      "TEST:  Loss: 0.44 Acc: 85.17%\n",
      "\n",
      "Epoch: 33/100     LR: 0.00768\n",
      "TRAIN: Loss: 0.64 Acc: 77.63%\n",
      "TEST:  Loss: 0.44 Acc: 85.05%\n",
      "\n",
      "Epoch: 34/100     LR: 0.00755\n",
      "TRAIN: Loss: 0.64 Acc: 77.96%\n",
      "TEST:  Loss: 0.43 Acc: 85.52%\n",
      "\n",
      "Epoch: 35/100     LR: 0.00741\n",
      "TRAIN: Loss: 0.63 Acc: 78.30%\n",
      "TEST:  Loss: 0.50 Acc: 83.58%\n",
      "\n",
      "Epoch: 36/100     LR: 0.00727\n",
      "TRAIN: Loss: 0.61 Acc: 78.60%\n",
      "TEST:  Loss: 0.44 Acc: 85.03%\n",
      "\n",
      "Epoch: 37/100     LR: 0.00713\n",
      "TRAIN: Loss: 0.62 Acc: 78.58%\n",
      "TEST:  Loss: 0.45 Acc: 85.38%\n",
      "\n",
      "Epoch: 38/100     LR: 0.00699\n",
      "TRAIN: Loss: 0.61 Acc: 78.82%\n",
      "TEST:  Loss: 0.50 Acc: 83.80%\n",
      "\n",
      "Epoch: 39/100     LR: 0.00684\n",
      "TRAIN: Loss: 0.60 Acc: 79.23%\n",
      "TEST:  Loss: 0.43 Acc: 85.41%\n",
      "\n",
      "Epoch: 40/100     LR: 0.00669\n",
      "TRAIN: Loss: 0.59 Acc: 79.68%\n",
      "TEST:  Loss: 0.42 Acc: 85.73%\n",
      "\n",
      "Epoch: 41/100     LR: 0.00655\n",
      "TRAIN: Loss: 0.58 Acc: 79.69%\n",
      "TEST:  Loss: 0.40 Acc: 86.64%\n",
      "\n",
      "Epoch: 42/100     LR: 0.00639\n",
      "TRAIN: Loss: 0.58 Acc: 79.97%\n",
      "TEST:  Loss: 0.39 Acc: 86.45%\n",
      "\n",
      "Epoch: 43/100     LR: 0.00624\n",
      "TRAIN: Loss: 0.58 Acc: 79.83%\n",
      "TEST:  Loss: 0.39 Acc: 86.87%\n",
      "\n",
      "Epoch: 44/100     LR: 0.00609\n",
      "TRAIN: Loss: 0.57 Acc: 80.36%\n",
      "TEST:  Loss: 0.36 Acc: 87.85%\n",
      "\n",
      "Epoch: 45/100     LR: 0.00594\n",
      "TRAIN: Loss: 0.56 Acc: 80.50%\n",
      "TEST:  Loss: 0.35 Acc: 88.04%\n",
      "\n",
      "Epoch: 46/100     LR: 0.00578\n",
      "TRAIN: Loss: 0.55 Acc: 80.93%\n",
      "TEST:  Loss: 0.36 Acc: 87.63%\n",
      "\n",
      "Epoch: 47/100     LR: 0.00563\n",
      "TRAIN: Loss: 0.55 Acc: 80.86%\n",
      "TEST:  Loss: 0.39 Acc: 86.62%\n",
      "\n",
      "Epoch: 48/100     LR: 0.00547\n",
      "TRAIN: Loss: 0.54 Acc: 81.42%\n",
      "TEST:  Loss: 0.35 Acc: 88.12%\n",
      "\n",
      "Epoch: 49/100     LR: 0.00531\n",
      "TRAIN: Loss: 0.53 Acc: 81.43%\n",
      "TEST:  Loss: 0.34 Acc: 88.68%\n",
      "\n",
      "Epoch: 50/100     LR: 0.00516\n",
      "TRAIN: Loss: 0.53 Acc: 81.66%\n",
      "TEST:  Loss: 0.34 Acc: 88.33%\n",
      "\n",
      "Epoch: 51/100     LR: 0.00500\n",
      "TRAIN: Loss: 0.52 Acc: 82.06%\n",
      "TEST:  Loss: 0.37 Acc: 87.54%\n",
      "\n",
      "Epoch: 52/100     LR: 0.00484\n",
      "TRAIN: Loss: 0.52 Acc: 82.08%\n",
      "TEST:  Loss: 0.35 Acc: 87.90%\n",
      "\n",
      "Epoch: 53/100     LR: 0.00469\n",
      "TRAIN: Loss: 0.50 Acc: 82.64%\n",
      "TEST:  Loss: 0.33 Acc: 88.63%\n",
      "\n",
      "Epoch: 54/100     LR: 0.00453\n",
      "TRAIN: Loss: 0.50 Acc: 82.69%\n",
      "TEST:  Loss: 0.36 Acc: 87.99%\n",
      "\n",
      "Epoch: 55/100     LR: 0.00437\n",
      "TRAIN: Loss: 0.49 Acc: 82.95%\n",
      "TEST:  Loss: 0.38 Acc: 87.72%\n",
      "\n",
      "Epoch: 56/100     LR: 0.00422\n",
      "TRAIN: Loss: 0.49 Acc: 82.92%\n",
      "TEST:  Loss: 0.31 Acc: 89.41%\n",
      "\n",
      "Epoch: 57/100     LR: 0.00406\n",
      "TRAIN: Loss: 0.49 Acc: 83.06%\n",
      "TEST:  Loss: 0.33 Acc: 88.76%\n",
      "\n",
      "Epoch: 58/100     LR: 0.00391\n",
      "TRAIN: Loss: 0.47 Acc: 83.56%\n",
      "TEST:  Loss: 0.31 Acc: 89.38%\n",
      "\n",
      "Epoch: 59/100     LR: 0.00376\n",
      "TRAIN: Loss: 0.48 Acc: 83.42%\n",
      "TEST:  Loss: 0.32 Acc: 89.29%\n",
      "\n",
      "Epoch: 60/100     LR: 0.00361\n",
      "TRAIN: Loss: 0.46 Acc: 83.98%\n",
      "TEST:  Loss: 0.30 Acc: 90.15%\n",
      "\n",
      "Epoch: 61/100     LR: 0.00345\n",
      "TRAIN: Loss: 0.46 Acc: 84.09%\n",
      "TEST:  Loss: 0.30 Acc: 90.03%\n",
      "\n",
      "Epoch: 62/100     LR: 0.00331\n",
      "TRAIN: Loss: 0.45 Acc: 84.16%\n",
      "TEST:  Loss: 0.30 Acc: 90.06%\n",
      "\n",
      "Epoch: 63/100     LR: 0.00316\n",
      "TRAIN: Loss: 0.45 Acc: 84.29%\n",
      "TEST:  Loss: 0.30 Acc: 90.27%\n",
      "\n",
      "Epoch: 64/100     LR: 0.00301\n",
      "TRAIN: Loss: 0.44 Acc: 84.86%\n",
      "TEST:  Loss: 0.30 Acc: 90.16%\n",
      "\n",
      "Epoch: 65/100     LR: 0.00287\n",
      "TRAIN: Loss: 0.44 Acc: 84.80%\n",
      "TEST:  Loss: 0.29 Acc: 90.35%\n",
      "\n",
      "Epoch: 66/100     LR: 0.00273\n",
      "TRAIN: Loss: 0.43 Acc: 84.90%\n",
      "TEST:  Loss: 0.27 Acc: 91.10%\n",
      "\n",
      "Epoch: 67/100     LR: 0.00259\n",
      "TRAIN: Loss: 0.42 Acc: 85.58%\n",
      "TEST:  Loss: 0.29 Acc: 90.73%\n",
      "\n",
      "Epoch: 68/100     LR: 0.00245\n",
      "TRAIN: Loss: 0.42 Acc: 85.57%\n",
      "TEST:  Loss: 0.27 Acc: 91.12%\n",
      "\n",
      "Epoch: 69/100     LR: 0.00232\n",
      "TRAIN: Loss: 0.41 Acc: 85.64%\n",
      "TEST:  Loss: 0.27 Acc: 91.00%\n",
      "\n",
      "Epoch: 70/100     LR: 0.00219\n",
      "TRAIN: Loss: 0.40 Acc: 85.93%\n",
      "TEST:  Loss: 0.27 Acc: 91.03%\n",
      "\n",
      "Epoch: 71/100     LR: 0.00206\n",
      "TRAIN: Loss: 0.40 Acc: 86.09%\n",
      "TEST:  Loss: 0.26 Acc: 91.48%\n",
      "\n",
      "Epoch: 72/100     LR: 0.00194\n",
      "TRAIN: Loss: 0.39 Acc: 86.29%\n",
      "TEST:  Loss: 0.25 Acc: 91.81%\n",
      "\n",
      "Epoch: 73/100     LR: 0.00181\n",
      "TRAIN: Loss: 0.39 Acc: 86.56%\n",
      "TEST:  Loss: 0.26 Acc: 91.34%\n",
      "\n",
      "Epoch: 74/100     LR: 0.00169\n",
      "TRAIN: Loss: 0.39 Acc: 86.59%\n",
      "TEST:  Loss: 0.26 Acc: 91.47%\n",
      "\n",
      "Epoch: 75/100     LR: 0.00158\n",
      "TRAIN: Loss: 0.38 Acc: 86.89%\n",
      "TEST:  Loss: 0.26 Acc: 91.45%\n",
      "\n",
      "Epoch: 76/100     LR: 0.00146\n",
      "TRAIN: Loss: 0.37 Acc: 87.05%\n",
      "TEST:  Loss: 0.25 Acc: 91.72%\n",
      "\n",
      "Epoch: 77/100     LR: 0.00136\n",
      "TRAIN: Loss: 0.38 Acc: 87.02%\n",
      "TEST:  Loss: 0.25 Acc: 91.97%\n",
      "\n",
      "Epoch: 78/100     LR: 0.00125\n",
      "TRAIN: Loss: 0.37 Acc: 87.07%\n",
      "TEST:  Loss: 0.24 Acc: 91.83%\n",
      "\n",
      "Epoch: 79/100     LR: 0.00115\n",
      "TRAIN: Loss: 0.36 Acc: 87.53%\n",
      "TEST:  Loss: 0.24 Acc: 91.91%\n",
      "\n",
      "Epoch: 80/100     LR: 0.00105\n",
      "TRAIN: Loss: 0.35 Acc: 87.62%\n",
      "TEST:  Loss: 0.24 Acc: 91.92%\n",
      "\n",
      "Epoch: 81/100     LR: 0.00095\n",
      "TRAIN: Loss: 0.35 Acc: 88.07%\n",
      "TEST:  Loss: 0.25 Acc: 91.94%\n",
      "\n",
      "Epoch: 82/100     LR: 0.00086\n",
      "TRAIN: Loss: 0.34 Acc: 88.12%\n",
      "TEST:  Loss: 0.24 Acc: 92.10%\n",
      "\n",
      "Epoch: 83/100     LR: 0.00078\n",
      "TRAIN: Loss: 0.34 Acc: 88.18%\n",
      "TEST:  Loss: 0.25 Acc: 91.92%\n",
      "\n",
      "Epoch: 84/100     LR: 0.00070\n",
      "TRAIN: Loss: 0.34 Acc: 88.33%\n",
      "TEST:  Loss: 0.23 Acc: 92.34%\n",
      "\n",
      "Epoch: 85/100     LR: 0.00062\n",
      "TRAIN: Loss: 0.33 Acc: 88.53%\n",
      "TEST:  Loss: 0.23 Acc: 92.58%\n",
      "\n",
      "Epoch: 86/100     LR: 0.00054\n",
      "TRAIN: Loss: 0.33 Acc: 88.57%\n",
      "TEST:  Loss: 0.23 Acc: 92.32%\n",
      "\n",
      "Epoch: 87/100     LR: 0.00048\n",
      "TRAIN: Loss: 0.33 Acc: 88.55%\n",
      "TEST:  Loss: 0.23 Acc: 92.39%\n",
      "\n",
      "Epoch: 88/100     LR: 0.00041\n",
      "TRAIN: Loss: 0.33 Acc: 88.68%\n",
      "TEST:  Loss: 0.23 Acc: 92.63%\n",
      "\n",
      "Epoch: 89/100     LR: 0.00035\n",
      "TRAIN: Loss: 0.32 Acc: 88.89%\n",
      "TEST:  Loss: 0.23 Acc: 92.55%\n",
      "\n",
      "Epoch: 90/100     LR: 0.00030\n",
      "TRAIN: Loss: 0.32 Acc: 88.99%\n",
      "TEST:  Loss: 0.22 Acc: 92.62%\n",
      "\n",
      "Epoch: 91/100     LR: 0.00024\n",
      "TRAIN: Loss: 0.31 Acc: 89.24%\n",
      "TEST:  Loss: 0.23 Acc: 92.56%\n",
      "\n",
      "Epoch: 92/100     LR: 0.00020\n",
      "TRAIN: Loss: 0.31 Acc: 89.19%\n",
      "TEST:  Loss: 0.23 Acc: 92.57%\n",
      "\n",
      "Epoch: 93/100     LR: 0.00016\n",
      "TRAIN: Loss: 0.32 Acc: 89.04%\n",
      "TEST:  Loss: 0.23 Acc: 92.47%\n",
      "\n",
      "Epoch: 94/100     LR: 0.00012\n",
      "TRAIN: Loss: 0.30 Acc: 89.41%\n",
      "TEST:  Loss: 0.22 Acc: 92.76%\n",
      "\n",
      "Epoch: 95/100     LR: 0.00009\n",
      "TRAIN: Loss: 0.31 Acc: 89.39%\n",
      "TEST:  Loss: 0.22 Acc: 92.79%\n",
      "\n",
      "Epoch: 96/100     LR: 0.00006\n",
      "TRAIN: Loss: 0.30 Acc: 89.59%\n",
      "TEST:  Loss: 0.22 Acc: 92.83%\n",
      "\n",
      "Epoch: 97/100     LR: 0.00004\n",
      "TRAIN: Loss: 0.31 Acc: 89.45%\n",
      "TEST:  Loss: 0.22 Acc: 92.88%\n",
      "\n",
      "Epoch: 98/100     LR: 0.00002\n",
      "TRAIN: Loss: 0.30 Acc: 89.42%\n",
      "TEST:  Loss: 0.22 Acc: 92.71%\n",
      "\n",
      "Epoch: 99/100     LR: 0.00001\n",
      "TRAIN: Loss: 0.31 Acc: 89.38%\n",
      "TEST:  Loss: 0.22 Acc: 92.76%\n",
      "\n",
      "Epoch: 100/100    LR: 0.00000\n",
      "TRAIN: Loss: 0.30 Acc: 89.65%\n",
      "TEST:  Loss: 0.22 Acc: 92.66%\n",
      "Model saved as ResNetCustom_epoch97_acc93.pth\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "try:\n",
    "    # Define optimizer\n",
    "    OPTIMIZER = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    \n",
    "    # Define scheduler\n",
    "    SCHEDULER = optim.lr_scheduler.CosineAnnealingLR(OPTIMIZER, T_max=EPOCHS)\n",
    "    \n",
    "    # If no scheduler, set to None\n",
    "    SCHEDULER = SCHEDULER if 'SCHEDULER' in locals() and SCHEDULER is not None else None\n",
    "\n",
    "    # train(model, EPOCHS)\n",
    "    train(model, EPOCHS, train_batch_size=TRAIN_BATCH_SIZE, test_batch_size=TEST_BATCH_SIZE, augmentations=AUGMENTATIONS,\n",
    "          optimizer=OPTIMIZER, scheduler=SCHEDULER, save=SAVE_MODE, every_n=SAVE_EVERY_N)\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(f'Training failed: {e}')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:21:23.674978Z",
     "iopub.status.busy": "2025-03-09T19:21:23.674615Z",
     "iopub.status.idle": "2025-03-09T19:21:27.300711Z",
     "shell.execute_reply": "2025-03-09T19:21:27.299803Z",
     "shell.execute_reply.started": "2025-03-09T19:21:23.674946Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading model...\n",
      "Running inference with batch_size=32...\n",
      "Predictions saved as ResNetCustom_epoch97_acc93.csv\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "try:\n",
    "    inference('ResNetCustom_epoch97_acc93.pth')\n",
    "except FileNotFoundError as e:\n",
    "    print(f'Inference failed: {e}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11145869,
     "sourceId": 93057,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
